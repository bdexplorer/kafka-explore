# see org.apache.kafka.clients.consumer.ConsumerConfig for more details

# list of brokers used for bootstrapping knowledge about the rest of the cluster
# format: host1:port1,host2:port2 ...
bootstrap.servers=localhost:9092

# consumer group id
group.id=test-consumer-group

# What to do when there is no initial offset in Kafka or if the current
# offset does not exist any more on the server: latest, earliest, none
#auto.offset.reset=

# 反序列化
key.deserializer
value.deserializer

enable.auto.commit=true
auto.commit.interval.ms = 5000

# lastest从分区末尾开始消费
# earliest 从消费者起始处消费
# none在查找不到消费位移的时候，会抛出异常NoOffsetForPartitionException。
auto.offset.reset = lastest

# 配置消费者和订阅主题之间的分区分配策略
# org.apache.kafka.clients.consumer.RangeAssignor （默认）
# org.apache.kafka.clients.consumer.RoundRobinAssignor
# org.apache.kafka.clients.consumer.StickyAssignor
# org.apache.kafka.clients.consumer.CooperativeStickyAssignor
partition.assignment.strategy = org.apache.kafka.clients.consumer.RangeAssignor

client.id

# 配置String类型的编码方式
key.deserializer.encoding
value.deserializer.encoding
deserializer.encoding

# consumer等待响应的超时时间
request.timeout.ms

interceptor.classes

# Consumer一次请求能从Kafka中拉取的最小数据量，默认1。
# 如果返回给Consumer的数据量小于这个值，那么需要等待。可以适当调大这个值，提高一定的吞吐量，不过也会造成额外的延迟
fetch.min.bytes = 1

# Consumer一次请求能从Kafka中拉取的最大数据量，默认52428800B。
# 该参数设置的不是绝对的最大值，如果第一个非空分区中拉取的第一条消息大于该值，那么将仍然返回，保证消费者正常工作。
# kafka所能接收的最大消息的大小通过服务端参数message.max.bytes设置（主题max.message.bytes）
fetch.max.bytes = 52428800

# 如果fetch.min.bytes一直不满足，则会等待fetch.max.wait.ms间隔
fetch.max.wait.ms = 500

# 与fetch.max.bytes类似
max.partition.fetch.bytes = 1048576

# 一次请求中拉取的最大消息数，如果消息的大小比较小，可以适当调大这个参数值来提升一定的消费速度。
max.poll.records = 500

# 多久关闭空闲的连接
connections.max.idle.ms = 540000

# __consumer_offsets 和__transaction_state内部主题是否向消费者公开。如果设置为true，只能通过subscribe(Collection)方式订阅
exclude.internal.topics = true

# SOCKET接收消息缓冲区的大小，不同机房可以适当调大。如果设置为-1，则使用操作系统默认值
receive.buffer.bytes = 65536

# 
send.buffer.bytes = 131072

# 配置元数据过期时间，如果元数据在此参数限定的范围内没有更新会被强制更新。
metadata.max.age.ms = 300000

# 配置尝试重新连接指定主机之前的等待时间，避免频繁连接主机
reconnect.backoff.ms = 50

# 配置尝试重新发送失败的请求到指定主题分区之前的等待时间，避免某些主题故障情况下频繁发送
retry.backoff.ms = 100

# 配置消费者的事务隔离级别。
# read_uncommitted可以消费到HW处，
# read_commited消费者会忽略未提交的消息，只能消费到（LSO）
isolation.level = read_uncommitted

# 当使用kafka分组管理功能时，心跳到消费者协调器之间的预计时间。通常比session.timeout.ms小，不高于1/3
heartbeat.interval.ms = 3000

# 组管理协议中用来检测消费者是否失效
session.timeout.ms = 10000

# 当通过消费者组管理消费者时，该配置指定拉取消息线程最长的空闲时间，如果超过这个时间还没有发起poll操作，消费者组认为该消费者已离开消费组，将进行再均衡操作
max.poll.interval.ms = 300000